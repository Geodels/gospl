{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward forward example\n",
    "\n",
    "\n",
    "This example will run in approximately **20 minutes**.\n",
    "\n",
    "To run the notebook several post and pre-processing librairies are required:\n",
    "\n",
    "+ panel\n",
    "+ pyvista\n",
    "+ pyevtk\n",
    "+ stripy\n",
    "\n",
    "To install these dependencies read the documentation in the [user guide](https://gospl.readthedocs.io/en/latest/user_guide/index.html#step-2-tutorials-via-jupyter-notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import meshio\n",
    "import meshplex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "import stripy as stripy\n",
    "from scipy import ndimage\n",
    "from netCDF4 import Dataset\n",
    "from scipy.spatial import cKDTree\n",
    "from scripts import getTecto as tec\n",
    "from scripts import readOutput as rout\n",
    "from gospl._fortran import definegtin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will run a global scale model starting from 15 Millions years ago to present. \n",
    "\n",
    "For running the experiment, we have the following dataset:\n",
    "\n",
    "1. a series of paleotopography maps at specific time interval (15 Ma, 5 Ma and 0 Ma) available in the folder `data/paleomap` as netCDF files.\n",
    "2. a series of paleoclimate precipitation maps at 5 Ma interval available in the folder `data/precipitation` as netCDF files.\n",
    "3. a series of plate velocities at 1 Ma interval available in the folder `data/velocity` as xy files.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>GOAL</b> Using these dataset, we will run a constrained landscape evolution model by using the paleotography maps at available time intervals to force the forward model with tectonic (uplift and subsidence) grids over time.\n",
    "</div>\n",
    "\n",
    "\n",
    "The example is mainly for illustration purposes. In most cases, the proposed method will require to be tuned over time by modifying the plate reconstructions, the paleotopography / paleoclimate maps and the model input parameters to refine the simulation results over time. Nevertheless, this notebook covers the main principles used during this process.\n",
    "\n",
    "\n",
    "## 1. Create gospl input dataset\n",
    "\n",
    "This first part takes approximately **5 minutes** to complete.\n",
    "\n",
    "### 1.1. Build gospl mesh\n",
    "\n",
    "\n",
    "For this example, we will build an icosahedral triangulation using the `stripy` library. To do so we will define a **refinement level** of 8 and store the newly created mesh in a folder named `input8`. \n",
    "\n",
    "`gospl` mesh needs the following information:\n",
    "\n",
    "- nodes coordinates\n",
    "- cells node indices\n",
    "- each node neighbours indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refinement level\n",
    "ref_lvl = 8\n",
    "\n",
    "# Build the folder in which all gospl input files will be stored\n",
    "dir_lvl = 'input'+str(ref_lvl)\n",
    "if not os.path.exists(dir_lvl):\n",
    "    os.makedirs(dir_lvl)\n",
    "    \n",
    "# Call stripy library\n",
    "if ref_lvl < 11:\n",
    "    grid = stripy.spherical_meshes.icosahedral_mesh(include_face_points=False, \n",
    "                                                    refinement_levels=ref_lvl)\n",
    "else:\n",
    "    grid = stripy.spherical_meshes.octahedral_mesh(include_face_points=False, \n",
    "                                                   refinement_levels=ref_lvl)\n",
    "\n",
    "str_fmt = \"{:25} {:9}\"\n",
    "print(str_fmt.format('Number of points', grid.lpoints))\n",
    "print(str_fmt.format('Number of cells', grid.simplices.shape[0]))\n",
    "\n",
    "# Take the unit sphere mesh and assign the Earth radius to the coordinates\n",
    "radius = 6378137.\n",
    "coords = np.vstack((grid.points[:,0],grid.points[:,1]))\n",
    "coords = np.vstack((coords,grid.points[:,2])).T\n",
    "coords = np.multiply(coords,radius)\n",
    "\n",
    "# Define mesh cells and nodes neighbourhood\n",
    "Gmesh = meshplex.MeshTri(coords, grid.simplices)\n",
    "s = Gmesh.idx_hierarchy.shape\n",
    "a = np.sort(Gmesh.idx_hierarchy.reshape(s[0], -1).T)\n",
    "if meshplex.__version__>= \"0.14.0\":\n",
    "    Gmesh.edges = {\"points\": np.unique(a, axis=0)}\n",
    "    ngbNbs, ngbID = definegtin(len(coords), Gmesh.cells('points'), \n",
    "                               Gmesh.edges['points'])\n",
    "else:\n",
    "    Gmesh.edges = {\"nodes\": np.unique(a, axis=0)}\n",
    "    ngbNbs, ngbID = definegtin(len(coords), Gmesh.cells['nodes'], \n",
    "                               Gmesh.edges['nodes'])\n",
    "    \n",
    "# Create mesh variables\n",
    "ngbIDs = ngbID[:,:8].astype(int)\n",
    "vertices = coords.copy()\n",
    "cells = grid.simplices\n",
    "\n",
    "# Convert spherical mesh longitudes and latitudes from radian to degree\n",
    "glat=np.mod(np.degrees(grid.lats)+90, 180.0)\n",
    "glon=np.mod(np.degrees(grid.lons)+180.0, 360.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Paleo and precipitation maps coordinates\n",
    "\n",
    "Paleo and precipitation dataset have different resolutions and we first map the newly created mesh coordinates on these two distinct resolutions:\n",
    "\n",
    "1. `coord1` for the paleo-elevation mesh\n",
    "2. `coord2` for the paleo-precipitation mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paleo-elevation\n",
    "elevfile = \"data/paleomap/0Ma.nc\"\n",
    "data1 = Dataset(elevfile, \"r\", format=\"NETCDF4\")\n",
    "img1 = np.fliplr(data1['z'][:,:].T)\n",
    "\n",
    "# Map mesh coordinates on this dataset\n",
    "lon1 = img1.shape[0] * glon / 360.0\n",
    "lat1 = img1.shape[1] * glat / 180.0\n",
    "coord1 = np.stack((lon1, lat1))\n",
    "meshlonlat = coord1/10.\n",
    "\n",
    "# Paleo-precipitation \n",
    "rainfile = \"data/precipitation/0Ma.nc\"\n",
    "data2 = Dataset(rainfile, \"r\", format=\"NETCDF4\")\n",
    "img2 = np.fliplr(data2['z'][:,:].T)\n",
    "\n",
    "# Map mesh coordinates on this dataset\n",
    "lon2 = img2.shape[0] * glon / 360.0\n",
    "lat2 = img2.shape[1] * glat / 180.0\n",
    "coord2 = np.stack((lon2, lat2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Interpolation of paleo dataset on gospl mesh\n",
    "\n",
    "The `buildPaleoMesh` function below is used to interpolate the paleogrid dataset (elevations and precipitations) on the gospl mesh. It takes the following arguments:\n",
    "\n",
    "- `time`: the time interval (here in Ma) to process\n",
    "- `dfolder`: the dataset folder containing the paleogrids to interpolate\n",
    "- `outfile`: the Numpy file created containing the interpolated values\n",
    "- `coords`: the coordinates of the mesh mapped on the dataset resolution\n",
    "- `rain`: set to True/False depending of the processed dataset\n",
    "- `visvtk`: set to True/False if one want to visualise the output as `VTK` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPaleoMesh(time, dfolder, outfile, coord=None, rain=False, visvtk=False, filter=2):\n",
    "    \n",
    "    paleof = dfolder+str(time)+\"Ma.nc\"\n",
    "    paleom = outfile+str(time)+\"Ma\"\n",
    "\n",
    "    paleodata = Dataset(paleof, \"r\", format=\"NETCDF4\")\n",
    "    \n",
    "    if rain:\n",
    "        paleod = paleodata['z'][:,:].T\n",
    "    else:\n",
    "        paleod = np.fliplr(paleodata['z'][:,:].T)\n",
    "    \n",
    "    # Apply some smoothing if necessary...\n",
    "    if filter>0:\n",
    "        paleod = ndimage.gaussian_filter(paleod,sigma=filter)\n",
    "\n",
    "    if rain:\n",
    "        # Interpolate the paleogrid on global mesh\n",
    "        meshd = ndimage.map_coordinates(paleod, coord, order=2, mode='nearest').astype(np.float64)\n",
    "        # Conversion from mm/day to m/yr\n",
    "        meshd *= 365.2422/1000.\n",
    "        # Save the mesh as compressed numpy file for global simulation\n",
    "        np.savez_compressed(paleom, r=meshd)\n",
    "    else:\n",
    "        # Interpolate the paleogrid on global mesh\n",
    "        meshd = ndimage.map_coordinates(paleod, coord , order=2, mode='nearest').astype(np.float64)\n",
    "        # Save the mesh as compressed numpy file for global simulation\n",
    "        np.savez_compressed(paleom, v=vertices, c=cells, n=ngbIDs.astype(int), z=meshd)\n",
    "        \n",
    "    print(\"Processing {} to create {} done\".format(paleof,paleom+\".npz\"))\n",
    "    \n",
    "    if visvtk:\n",
    "        paleovtk = outfile+str(time)+\"Ma.vtk\"\n",
    "        if rain:\n",
    "            vis_mesh = meshio.Mesh(vertices, {'triangle': cells}, point_data={\"r\":meshd})\n",
    "        else:\n",
    "            vis_mesh = meshio.Mesh(vertices, {'triangle': cells}, point_data={\"z\":meshd})\n",
    "        meshio.write(paleovtk, vis_mesh)\n",
    "        print(\"Writing VTK file {}\".format(paleovtk))\n",
    "\n",
    "    return\n",
    "\n",
    "# Paleo-elevations\n",
    "efolder = \"data/paleomap/\"\n",
    "efile = dir_lvl+\"/elev\"\n",
    "buildPaleoMesh(0, efolder, efile, coord=coord1, rain=False, visvtk=False)\n",
    "buildPaleoMesh(5, efolder, efile, coord=coord1, rain=False, visvtk=False)\n",
    "buildPaleoMesh(15, efolder, efile, coord=coord1, rain=False, visvtk=True)\n",
    "\n",
    "# Paleo-precipitation \n",
    "rfolder = \"data/precipitation/\"\n",
    "rfile = dir_lvl+\"/rain\"\n",
    "buildPaleoMesh(0, rfolder, rfile, coord=coord2, rain=True, visvtk=False)\n",
    "buildPaleoMesh(5, rfolder, rfile, coord=coord2, rain=True, visvtk=False)\n",
    "buildPaleoMesh(10, rfolder, rfile, coord=coord2, rain=True, visvtk=False)\n",
    "buildPaleoMesh(15, rfolder, rfile, coord=coord2, rain=True, visvtk=False)\n",
    "\n",
    "\n",
    "# Check the mesh validity by loading the created VTK file \n",
    "mesh = pv.read('input8/elev15Ma.vtk')\n",
    "elev = mesh.get_array(name='z')\n",
    "scale = 20.\n",
    "factor = 1.+ (elev/radius)*scale\n",
    "mesh.points[:, 0] *= factor\n",
    "mesh.points[:, 1] *= factor\n",
    "mesh.points[:, 2] *= factor\n",
    "contour = mesh.contour([0])\n",
    "plot = pv.PlotterITK()\n",
    "plot.add_mesh(mesh, scalars=\"z\")\n",
    "plot.add_mesh(contour, color=\"black\", opacity=1.)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Velocity fields on gospl mesh\n",
    "\n",
    "We will now read the paleo-displacement grids stored in the `data/velocity` as xy files.\n",
    "\n",
    "These velocities have been obtained from the gPlates web protal (in cm/yr) and have a specific format, we will use `pandas` library to parse these files. \n",
    "\n",
    "To get X,Y,Z velocities on `gospl` mesh, we will define a kdTree using `ScipPy` spatial `cKDTree` function and for simplicity we will use the closest point indice to assign the velocity on each node of the triangulation.  \n",
    "\n",
    "First we build the tree and find the closest indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the 3D displacement maps (xy files) and store it as a pandas dataframe\n",
    "dir_vel = 'data/velocity'\n",
    "gPlates = dir_vel+'/velocity_0.00Ma.xy'\n",
    "data = pd.read_csv(gPlates, sep=r'\\s+', engine='c', \n",
    "                   header=None, skiprows=[0,1,2,3,4,5,65166],\n",
    "                   error_bad_lines=True, na_filter=False, \n",
    "                   dtype=np.float64, low_memory=False)\n",
    "\n",
    "vlon = data.values[:,0]+180.\n",
    "vlat = data.values[:,1]+90.\n",
    "\n",
    "# Build the kdtree\n",
    "tree = cKDTree(list(zip(vlon, vlat)))\n",
    "dist, closeID = tree.query(list(zip(meshlonlat[0,:], meshlonlat[1,:])), k = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then call the `nearestPaleoDisp` function below to build the displacement files induced by the moving plates required by `gospl`. \n",
    "\n",
    "This function takes the following arguments:\n",
    "\n",
    "- `gPlates`: the input velocity file name\n",
    "- `outfile`: the Numpy file created containing the interpolated velocity values\n",
    "- `dfolder`: the dataset folder containing the paleogrids to interpolate\n",
    "- `reverse`: set to True/False depending of the type of model that is ran either backward (True) or forward (False)\n",
    "- `visvtk`: set to True/False if one want to visualise the output as `VTK` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestPaleoDisp(gPlates=None, outfile=None, reverse=False, visvtk=False):\n",
    "    '''\n",
    "    Reading paleo-displacement grids\n",
    "    '''\n",
    "\n",
    "    # Open gPlates 1 degree 3D displacement maps (xy files)\n",
    "    data = pd.read_csv(gPlates, sep=r'\\s+', engine='c', header=None, skiprows=[0,1,2,3,4,5,65166], \n",
    "                       error_bad_lines=True, na_filter=False, dtype=np.float64, low_memory=False)\n",
    "    \n",
    "    # Conversion from cm/yr to m/yr\n",
    "    if reverse:\n",
    "        tmpx = -data.values[:,2]/100.\n",
    "        tmpy = -data.values[:,3]/100.\n",
    "        tmpz = -data.values[:,4]/100.\n",
    "    else:\n",
    "        tmpx = data.values[:,2]/100.\n",
    "        tmpy = data.values[:,3]/100.\n",
    "        tmpz = data.values[:,4]/100.\n",
    "    \n",
    "    # Interpolate the paleo displacement on global mesh\n",
    "    dX = tmpx.flatten()[closeID].reshape(meshlonlat[0,:].shape)\n",
    "    dY = tmpy.flatten()[closeID].reshape(meshlonlat[0,:].shape)\n",
    "    dZ = tmpz.flatten()[closeID].reshape(meshlonlat[0,:].shape)\n",
    "\n",
    "    disps = np.stack((dX, dY, dZ)).T\n",
    "\n",
    "    # Save the mesh as compressed numpy file for global simulation\n",
    "    np.savez_compressed(outfile, xyz=disps)\n",
    "\n",
    "    if visvtk:\n",
    "        vis_mesh = meshio.Mesh(vertices, {'triangle': cells}, point_data={\"ux\":dX,\"uy\":dY,\"uz\":dZ})\n",
    "        meshio.write(outfile+\".vtk\", vis_mesh)\n",
    "        print(\"Writing VTK file {}\".format(outfile+\".vtk\"))\n",
    "\n",
    "    print(\"Processing {} to create {}\".format(gPlates,outfile+\".npz\"))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will apply the function over a 1 Ma increment for both backward and forward models. The function will create displacement file at the same temporal resolution (1 Ma) with 3D displacements in m/yr corresponding to the plate velocities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify most recent time in Ma\n",
    "startMa = 0\n",
    "# Specify deepest time in Ma\n",
    "endMa = 15\n",
    "# Specify paleodisp interval\n",
    "dtMa = 1\n",
    "\n",
    "timeframe = np.arange(startMa,endMa+dtMa,dtMa)\n",
    "\n",
    "p = timeframe[0]\n",
    "for k in range(len(timeframe)):\n",
    "    f_gplates = dir_vel+'/velocity_'+str(k+p)+'.00Ma.xy'\n",
    "    paleo_disp = dir_lvl+'/disp'+str(k+p)+'Ma'\n",
    "    paleo_backdisp = dir_lvl+'/backdisp'+str(k+p)+'Ma'\n",
    "    nearestPaleoDisp(gPlates=f_gplates, outfile=paleo_disp, reverse=False, visvtk=False) \n",
    "    nearestPaleoDisp(gPlates=f_gplates, outfile=paleo_backdisp, reverse=True, visvtk=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run gospl\n",
    "\n",
    "This step takes about **10 minutes** to complete.\n",
    "\n",
    "Running `gospl` is done by calling the `runBF.py` script. \n",
    "\n",
    "\n",
    "The Python script will do the following:\n",
    "\n",
    "1. run the backward models (using the `backward15Ma.yml` and `backward10Ma.yml` input files). The backward models do not have surface processes activated and only the backward displacements computed above are used to move the elevation over time.  \n",
    "2. combine each backward model outputs together using the `scripts/mergeBack.py` file.\n",
    "3. run the forward model (using the `forward.yml` input file). This model accounts for climatic forcing, tectonic forcing and surface processes. Also it will for each 1 million year interval compute the differences between the simulated elevation and the backward ones and apply a scaling factor to force the elevations to approach the paleo-elevations at 5 and 15 Ma. The computed scaled differences are reapplied at the previous  time step as a vertical tectonic map.\n",
    "\n",
    "\n",
    "You can open the input files to look at the parameters that are setup for this example. A complete list of the `gospl` input variables is available in the [user guide](https://gospl.readthedocs.io/en/latest/user_guide/inputfile.html) documentation.\n",
    "\n",
    "----\n",
    "\n",
    "A series of 3 input files are provided and can be used to run backward and forward models. The 2 backward models are divided in steps:\n",
    "\n",
    "1. `backward15Ma.yml` runs from 15 Ma to 10 Ma in *model time* but corresponds in *real time* in a backward model starting at 0 Ma and running back to 5 Ma ago;\n",
    "2. `backward10Ma.yml` goes from 10 Ma to 0 Ma in *model time*, *i.e.* 5 Ma ago to 15 Ma ago in *real time*.\n",
    "\n",
    "When looking at these input files pay attention at the order of the tectonic meshes that force the model. It is also worth mentioning that for these backward models we do not compute the surface processes as a result we set `fast` and `backward` to **True**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a single processor...\n",
    "#%run runBF.py \n",
    "\n",
    "# In parallel...\n",
    "!mpirun -np 4 python3 runBF.py  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisation in a notebook environment\n",
    "\n",
    "The preferred way for visualising the model output is via `Paraview` by loading the time series file called `gospl.xdmf` available in the output folder (here called `forward`). A Paraview file is also provided: `pvstate.pvsm`. It can be loaded as a state in `Paraview` and should work once the relative path of the `gospl.xdmf` file has been correctly defined to match with your local repository structure.\n",
    "\n",
    "Amongst the temporal variables outputed by `gospl` you will find:\n",
    "\n",
    "- surface elevation elev.\n",
    "- cumulative erosion & deposition values erodep.\n",
    "- flow accumulation flowAcc before pit filling.\n",
    "- flow accumulation fillAcc for depressionless surface.\n",
    "- river sediment load sedLoad.\n",
    "- fine sediment load sedLoadf when dual lithologies are accounted for.\n",
    "- uplift subsidence values if vertical tectonic forcing is considered uplift.\n",
    "- horizontal displacement values when considered hdisp.\n",
    "- precipitation maps based on forcing conditions rain.\n",
    "\n",
    "Several filters, rendering and calculation can be done with `Paraview` but are beyond the scope of this example. \n",
    "\n",
    "Here you will use the `readOutput.py` functions available in the `scripts` folder to visualise directly the model output in the notebook at the final time step.\n",
    "\n",
    "The function requires several arguments:\n",
    "\n",
    "- `filename`: the name of the input file\n",
    "- `step`: the step you wish to output (here set to 15 corresponding to the last output based on the input parameters: start time 15 Ma, end time present with an output every 1 million year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the final output generated by gospl\n",
    "output = rout.readOutput(filename='forward.yml',step=15)\n",
    "\n",
    "# Exporting the final output as a VTK mesh\n",
    "output.exportVTK('step15.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualise the `VTK` output in the notebook directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = pv.read('step15.vtk')\n",
    "elev = mesh.get_array(name='elev')\n",
    "\n",
    "earthRadius = 6.371e6\n",
    "scale = 20.\n",
    "factor = 1.+ (elev/earthRadius)*scale\n",
    "\n",
    "mesh.points[:, 0] *= factor\n",
    "mesh.points[:, 1] *= factor\n",
    "mesh.points[:, 2] *= factor\n",
    "\n",
    "contour = mesh.contour([0])\n",
    "\n",
    "plot = pv.PlotterITK()\n",
    "plot.add_mesh(mesh, scalars=\"elev\")\n",
    "plot.add_mesh(contour, color=\"black\", opacity=1.)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export vertical displacements\n",
    "\n",
    "\n",
    "Here, we illustrate how we can extract some of `gospl` output variables using some Python functions.  \n",
    "\n",
    "As an example, the `scripts/getTecto.py` function can export the computed vertical tectonic rates (uplift and subsidence) obtained from the backward/forward model and create vertical tectonic input files (`input8/vdispXMa.npz`) that can be directly applied to the forward model without having to run it in **backward/forward** mode.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the tectonic class\n",
    "tect = tec.getTecto(filename='forward.yml')\n",
    "\n",
    "# Define simulation time intervals in Ma\n",
    "startMa = 0\n",
    "endMa = 15\n",
    "\n",
    "# Specify paleodisp interval\n",
    "dtMa = 1\n",
    "timeframe = np.arange(startMa,endMa+dtMa,dtMa)\n",
    "timeframe = np.flip(timeframe)\n",
    "\n",
    "# Create the vertical tectonic input files over time\n",
    "tect.readData(out=dir_lvl+'/vdisp',time=timeframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check one of the tectonic input file values by creating a `VTK` file and plotting it in the Jupyter notebook... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkvtk = dir_lvl+'/vtec15Ma.vtk'\n",
    "etopofile = dir_lvl+'/elev15Ma.npz'\n",
    "topo = np.load(etopofile)\n",
    "elev = topo['z']\n",
    "\n",
    "vdispfile = dir_lvl+'/vdisp15Ma.npz'\n",
    "data = np.load(vdispfile)\n",
    "vdisp = data['z']\n",
    "\n",
    "vis_mesh = meshio.Mesh(vertices, {'triangle': cells}, point_data={\"Z\":elev, \"vTec\":vdisp})\n",
    "meshio.write(checkvtk, vis_mesh)\n",
    "\n",
    "print(\"Writing VTK file {}\".format(checkvtk))\n",
    "\n",
    "# Plot the tectonic vertical forcing by loading the created VTK file \n",
    "mesh = pv.read(checkvtk)\n",
    "elev = mesh.get_array(name='Z')\n",
    "scale = 20.\n",
    "factor = 1.+ (elev/radius)*scale\n",
    "mesh.points[:, 0] *= factor\n",
    "mesh.points[:, 1] *= factor\n",
    "mesh.points[:, 2] *= factor\n",
    "contour = mesh.contour([0])\n",
    "plot = pv.PlotterITK()\n",
    "plot.add_mesh(mesh, scalars=\"vTec\")\n",
    "plot.add_mesh(contour, color=\"black\", opacity=1.)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
